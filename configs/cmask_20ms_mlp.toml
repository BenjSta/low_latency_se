batch_size=64
fs = 16000
train_seq_duration = 4.0
lr_start = 0.0003
lr_stop = 0.00001
lr_update_interval = 1000
val_interval = 20000
max_steps = 500000
num_workers = 14
data_distribution_seed = 1

[model]
hopsize = 160
algorithmic_delay_nn=320
winlen = 320
method = "complex_filter"
use_mlp = true
num_filter_frames = 1
learnable_transforms = true
downsample_factor = 1

[model.crn_config]
num_channels_encoder = [2, 16, 32, 64, 104]
kernel_sizes = [[5, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3]]
fstride = 2
n_gru_layers = 1
n_gru_groups = 4
nonlinearity = "ELU"
batch_norm = false

[loss]
winlen = 320
complex_weight = 0.3
f_fade_out_complex_low = 3000
f_fade_out_complex_high = 4500

[data_distribution]
snr_mu_and_sigma=[15, 10]
speech_rms_mu_and_sigma=[-20, 7]
apply_noise=true
rir_percentage=0.75







